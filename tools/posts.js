let fs = require('fs-extra');
let rp = require('request-promise');

const config = JSON.parse(fs.readFileSync('config.json', 'utf8'));

/* 
	Fields we want to fetch for each post.
	For a full list of available fields, see:
	https://developers.facebook.com/docs/graph-api/reference/v2.11/post
*/
const post_fields = [
	// the unique identifier for the post
	'id',

	// the content of the post
	'message',

	// the time at which the post was created
	'created_time',

	// the object type of the post
	'type', // One of: link, status, photo, video, offer

	// Description of the type of a status update.
	// One of: mobile_status_update, created_note, 
	// added_photos, added_video, shared_story, created_group, 
	// created_event, wall_post, app_created_story, published_story, 
	// tagged_in_photo, approved_friend
	'status_type', 

	// Text from stories not intentionally generated by users, 
	// such as those generated when two people become friends, 
	// or when someone else posts on the person's wall.
	'story',

	// the link attached to the post
	'link',

	// the picture and description for the link attached to the post
	// (these are usually scraped by the Facebook crawler)
	'picture',
	'description',

	// the reactions / shares your post got
	'shares',
	'likes',
	'reactions',
	'sharedposts',

	// the list of (nested) comments on your posts;
	// notice the subfields stated in braces
	'comments{comments,created_time,from,message}',

	// any attachments for the posts (a set of images, a video, etc.)
	'attachments'
];

fetch_posts(`https://graph.facebook.com/v2.11/me/posts?access_token=${config.access_token}&fields=${encodeURIComponent(post_fields.join(','))}`, 'export/json/posts.json');

/* 
	Functions
	------------------------------------------------------------
*/

/*
	Given a link to the API endpoint, and a file to write the output to,
	fetch the posts for the current user.
*/
function fetch_posts(api, outFile) {

	/*
		We will need a queue for all the URLs we want to fetch,
		since the API is paginated. At first, the only thing
		in the queue is the URL for the API endpoint, but we'll
		place here the links to the next pages, as well.
	*/
	let url_queue = [api];
	fetch_posts_page(url_queue, function(data) {
		// When finished, output the array of posts to the specified $outFile.
		fs.outputFile(outFile, JSON.stringify(data, null, 2));
		console.info(`Exported ${data.length} posts to ${outFile}`);
	});
};

/*
	Given a queue of URLs, and a callback function,
	this function fetches the posts associated with each URL in the queue,
	and then calls the callback when the queue is exhausted.
*/

function fetch_posts_page(pages_queue, callback, accumulator = []) {
	// Check to see if there are any URLs left in the queue
	if (pages_queue.length) {

		// If so, grab the first one and take it out of the queue
		let uri = pages_queue.shift();
		console.log(`Fetching: ${uri} \n`);

		rp({
			uri: uri,
			json: true
		}).then(response => {

			// When we get the response, place the `response.paging.next` URL 
			// if there's any available, and concatenate the posts
			// with the accumulating array.

			fetch_posts_page(
				pages_queue.concat(
					response.paging && response.paging.next ? 
						[response.paging.next] : []
				), callback, accumulator.concat(response.data));
		});

	} else {

		// Finally, when the queue is empty, execute the callback function
		// with the accumulator array (the one containing all the fetched posts)
		callback(accumulator);
	}
}

